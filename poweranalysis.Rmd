---
title: "Poweranalysis"
author: "CK"
date: "24/08/2020"
output: 
 bookdown::html_document2:
  fig_caption: yes
  toc: yes
  toc_float: true
  number_sections: false
 bookdown::word_document2:
 bookdown::pdf_document2:
   keep_tex: true
editor_options: 
  chunk_output_type: console
#always_allow_html: true
knit: (function(input_file, encoding) {
  out_dir <- 'docs';
  rmarkdown::render(input_file,
  encoding=encoding,
  output_file=file.path(dirname(input_file), out_dir, 'index.html'))})
bibliography: "library.bib"
biblio-style: "apalike"
link-citations: yes  
---

# The data set  
The data consists of measurements of 36 pasture-soil samples (0－10cm) which are historically contaminated with dieldrin residues. Dieldrin is extremely persistent and therefore still found in the surface soil after three decades of natural attenuation.  
  
The samples were taken in 12 paddocks in two different soils, with three field replicates at representative areas of each paddock.  So overall the data consists of:   
  
- 2 soils
  - 12 paddocks (7 + 5)
    - 36 samples (3 per paddock, 21 + 15)  
**Each sample is a composite of 8-10 soil cores which represents and area of the paddock.**  
  
Total dieldrin loss (%) since 24-30 years was recorded per paddock. Thus, dieldrin residue concentrations (µg/g soil) and other soil measurements were measured for all samples (n = 36) but dieldrin loss (%) was available per paddock only (n = 12). 
  
**Data table (n = 36):**
```{r setup, include=TRUE, message=FALSE, echo=FALSE}
library(tidyverse)
library(rcompanion)
library(pwr)
library(rstatix)

# Get some data
metadata<- readr::read_tsv("~/Documents/Study/LaTrobe/Research/phD/Milestone2_Field_Survey/M2_Bacteria/M2_Qiime_output_Bacteria2020run/metadata.tsv") 

# Change to your liking
metadata2 <- metadata[c(2:nrow(metadata)),c(1:length(metadata))] %>%
  tibble::rownames_to_column("spl") %>%
  dplyr::mutate_all(type.convert) %>%
  dplyr::mutate_if(is.factor, as.character) %>%
  tibble::column_to_rownames("spl")

metadata2$Soil <- recode_factor(metadata2$Soil, '1' = 'Kurosol', '2' = 'Chromosol')

# Some rows and 10 columns as overview of data. Only some of the measurements are shown.
options(knitr.kable.NA = '')
kableExtra::kable(metadata2[c(1:5,22:27),c(1:4,6,10,11,13,14,15,17)]) %>% kableExtra::kable_styling(full_width = F, position = "left",bootstrap_options = c( "condensed"), font_size = 11 )

```
  
## Dieldrin concentrations  
**Dieldrin concentrations (n=36) were approximately log-normal**
```{r shapiro, include=TRUE, message=FALSE, echo=FALSE}  
# Test normality of dieldrin concentrations n = 36
shapiro.test(log10(metadata2$D1517))  # aprox lognormal
```
  

**Distribution of dieldrin concentrations (log-scale)**
```{r boxplots, include=TRUE, message=FALSE, echo=FALSE, fig.width=8, fig.asp=0.6} 
# Boxplot of dieldrin concentrations across all 36 samples and then by soil type
p1 <- metadata2 %>% ggpubr::ggboxplot(y = "D1517", add="jitter", ylab = "Dieldrin concentrations (µg/g soil)", add.params = list(shape = "Soil"), yscale = "log10")

p2 <- metadata2 %>% ggpubr::ggboxplot(y = "D1517", x = "Soil", add="jitter", ylab = "Dieldrin concentrations (µg/g soil)", shape = "Soil", yscale = "log10")

ggpubr::ggarrange(p1, p2)
```

  
**Dieldrin concentrations per soil and paddock:**
```{r dieldrincc, include=TRUE, message=FALSE, echo=FALSE}


options(knitr.kable.NA = '')
kableExtra::kable(metadata2 %>%
  group_by(Soil) %>%
  get_summary_stats(D1517, type = "mean_sd") %>% rename(Dieldrin = variable ) ) %>% kableExtra::kable_styling(full_width = F, position = "left",bootstrap_options = c( "condensed"), font_size = 11 )


# Mean dieldrin concentrations per paddock
options(knitr.kable.NA = '')
kableExtra::kable(metadata2 %>%
  group_by(Paddock) %>%
  get_summary_stats(D1517, type = "mean_se")  %>% rename(Dieldrin = variable ) )%>% kableExtra::kable_styling(full_width = F, position = "left",bootstrap_options = c( "condensed"), font_size = 11 )
```
  
## Total dieldrin loss (%)

**Dieldrin losses (%) since 1988  were approximately normal (n=12)**
```{r shapiroloss, include=TRUE, message=FALSE, echo=FALSE}  
# Test normality of dieldrin concentrations n = 36

metadata2 %>%
  group_by(Paddock) %>% summarise(Dloss = mean(Dloss)) %>%  rstatix::shapiro_test(Dloss)
```

**Distribution of dieldrin loss (%)**
```{r boxplotsloss, include=TRUE, message=FALSE, echo=FALSE, fig.width=8, fig.asp=0.6} 
# Boxplot of dieldrin concentrations across all 36 samples and then by soil type
p1 <- metadata2 %>%  group_by(Soil, Paddock) %>% summarise(Dloss = mean(Dloss)) %>% ggpubr::ggboxplot(y = "Dloss", add="jitter", ylab = "Dieldrin loss (%)", add.params = list(shape = "Soil"))

p2 <-  metadata2 %>%  group_by(Soil, Paddock) %>% summarise(Dloss = mean(Dloss)) %>% ggpubr::ggboxplot(y = "Dloss", x = "Soil", add="jitter", ylab = "Dieldrin loss (%)", add.params = list(shape = "Soil"))

ggpubr::ggarrange(p1, p2)
```

**Total dieldrin loss since 1988 (%) per soil and paddock:**  
Total dieldrin loss was recorded per paddock only (n = 12)
```{r dieldrinloss, include=TRUE, message=FALSE, echo=FALSE}  

kableExtra::kable(metadata2 %>%
  group_by(Soil) %>%
  get_summary_stats(Dloss, type = "mean_sd")  %>% rename(Dieldrinloss = variable )) %>% kableExtra::kable_styling(full_width = F, position = "left",bootstrap_options = c( "condensed"), font_size = 11 )


# Mean dieldrin losses per paddock
# There is no standard error within each paddock - as the values for dieldrin loss were collected per paddock, not per sample
kableExtra::kable(metadata2 %>%
  group_by(Paddock) %>%
  get_summary_stats(Dloss, type = "mean_se")  %>% rename(Dieldrinloss = variable )) %>% kableExtra::kable_styling(full_width = F, position = "left",bootstrap_options = c( "condensed"), font_size = 11 )

```
  

# Power analysis 
  
**Questions:**   
  
1. From the available 36 samples (21 for soil 1 and 15 for soil 2), **how much power does a suitable test have** to determine if there are significant differences between the two soils? If I understand power correctly, then it is the chance of getting a significant results i.e. power = percent(<=0.05).  
2. **How many samples are needed** per sample to get the true mean of dieldrin concentrations?  
3. **How many paddocks are needed** to model biological data to dieldrin loss?  
  
**Some reading**   
- Statistical power analysis: A simple and general model for traditional and modern hypothesis tests [@Murphy2014]  
- Statistical Power Analysis [@Cohen1992]  
- Bootstrap Methods and their Application [@Davison1997] 

**Videos**  
- [Bootstrap Confidence Interval with R | R Video Tutorial 4.5](https://www.youtube.com/watch?v=Om5TMGj9td4)

  
## Question 1
**How much power does the result have?**
The following is based on the pwr package vignette:  
https://cran.r-project.org/web/packages/pwr/vignettes/pwr-vignette.html

### t-test  
An option to answer question 1: How powerful is this experiment if we want to detect a “large” effect in either direction with a significance level of 0.05  
```{r powert, include=TRUE, message=FALSE, echo=TRUE}
# Effect size large = 0.8

pwr.t.test(n = 15, d = 0.8, sig.level = 0.05)
pwr.t.test( d = 0.8, sig.level = 0.05, power = 0.8)
```

Result:  
The sample size is uneven between the two soils (n= 21, n = 15) so the t-test is not suitable. However, doing it anyway and using the lower number of n (n = 15) and a large effect size (how do we actually calculate d for t-tests as 0 -1?), the power of a t-test would be relatively low (power = 0.56).  
  
If we wanted to redo this experiment (using equal sample sizes) 25 samples per soil are needed to test for significant differences at a power of 0.8.  

  
<br/>

### Resampling of mean dieldrin concentrations  
An option to answer question 1: Calculate the power of getting the true mean of dieldrin concentrations from the pilot (n = 36). Resample 1000x across both soils and calculate mean and std of dieldrin concentrations. 
```{r resampleexample, include=TRUE, message=FALSE, warning=FALSE, fig.width=17, fig.asp=0.4, cache=TRUE}

# Notes 

#calc mean and std 1000 x
# calc distr. of means and std
# variation from the mean
# sample size less 30 - t distribution
# look up the table
# simulations

B = 1000
measurement = 'D1517'

# The mean mean function
## This function takes a dataframe that contained columns which we want to measure and then uses the rstatix package to get the mean.  
meanfunction <- function(df){
df %>% rstatix::get_summary_stats(measurement, type = "mean")  
}

# Function to randomly resample the mean with replacement and get a df with the mean of each resample
## It takes a dataframe with a column we want to resample and uses the meanfunction and applies that to the column B number of times. The output is a dateframe which lists the mean in B x number of rows.
listfunction <- function(df){
listdf <- replicate(B, dplyr::slice_sample(df, n= n, replace = TRUE), simplify = FALSE) %>%
  lapply(., meanfunction) %>% 
  bind_rows  
return(listdf)
}

# Function to get a summary statistic of the mean
## This function takes the dataframe produced by the listfunction and produces a summary statistic for it
summaryfunction <- function(listdf){
  listdf %>% rstatix::get_summary_stats(mean, type = "common")
}


# Function to get a historgram of the means
## This function takes the dataframe produced by the listfunction and produces a histogram for it
histofunction <- function(summarydf){
plotting <- summaryfunction(summarydf)
  summarydf %>% ggpubr::gghistogram(x= "mean", title = paste(B,"x resampled with n =", n, ", mean =", plotting$mean, "stdv =", plotting$sd))
}


# n=10
n = 10 # number of samples to resample every time 
set.seed(111)
summarydf <- listfunction(metadata2)
summaryfunction(summarydf)
p10 <- histofunction(summarydf)

# n=15
n = 15 # number of samples to resample every time 
set.seed(111)
summarydf <- listfunction(metadata2)
summaryfunction(summarydf)
p15 <- histofunction(summarydf)

# n=20
n = 20 # number of samples to resample every time 
set.seed(111)
summarydf <- listfunction(metadata2)
summaryfunction(summarydf)
p20 <- histofunction(summarydf)

ggpubr::ggarrange(p10, p15, p20, nrow = 1)
```
  
Lets say we take the mean and SD from the resampling with n = 20 and calculate the chance that the mean was outside the 2 SDs (outside of 95% of all probabilities). In other words, assuming the distribution was normal, how often does the mean fall outside the 95% of the resampled mean population?   
  
So of the 1000 resamples calculate the percentage of times that the mean values are above 2xSD and below 2xSD. 
In other words how many times until we get P( (X < (µ - 2SD)) + (X > (µ - 2SD)) ) = 0.05 
```{r, include=TRUE, message=FALSE, warning=FALSE}
result <- mean( (summarydf %>% dplyr::select(mean)) > (summaryfunction(summarydf)$mean + (2*summaryfunction(summarydf)$sd)) ) + 
  mean( (summarydf %>% dplyr::select(mean)) < (summaryfunction(summarydf)$mean - 2*summaryfunction(summarydf)$sd) )

print(paste("Result: There is a ",result*100, "% chance the sampled mean falls outside the significant of 0.05. So based on a normal distribution the power is", (1-result)*100, "?"))
```


 
**Here the same formula is applied to dieldrin losses (n= 12):**
```{r robustsamplesize2,  include=TRUE, message=FALSE, echo=TRUE}
# n = ((2 x STD) / SE )^2
data <- metadata2 %>% group_by(Paddock) %>% summarise(Dlossmean = mean(Dloss), CNmean = mean(CN))
sum_stat <- data %>% rstatix::get_summary_stats(Dlossmean, show = c("mean", "sd", "se"))
n = ( (2 * sum_stat$sd) / sum_stat$se )^2
# n = 48 samples needed for the mean dieldrin loss  to be robust
n 
```
Accordingly, 48 samples were needed for the mean dieldrin loss to be robust

  
## Question 2
#### F-test  
**How many samples are needed?**
An option to answer question 2: How many samples are needed? There are different options and am currently only exploring this... 
```{r powerf, include=TRUE, message=FALSE, echo=TRUE}

# Calculate the number of samples needed to model Dlossmean (12 samples) with CN as predictor
# https://cran.r-project.org/web/packages/pwr/vignettes/pwr-vignette.html
# The effect size is the R2 of the model. the coefficient of determination, aka the “proportion of variance explained”
pwr.f2.test(u = 1, f2 = 0.5/(1 - 0.5), sig.level = 0.001, power = 0.8)
#n = v + u + 1
# n = 21 + 1 + 1 = 22 paddocks needed at an effect size of 0.5

```

<br/>

### Or just use a simplified formula? 
An option to answer question 2: The following is based on http://r-video-tutorial.blogspot.com/2017/07/power-analysis-and-sample-size.html  
Using:
$$N = {2 * SD \choose SE}^2$$
This is approximately at 95% confidence where N is the number of samples, SD the standard deviation and SE is the standard error. These values can be obtained from previous experiments, or from the literature
```{r robustsamplesize,  include=TRUE, message=FALSE, echo=FALSE}
# samples (n) needed for a rubust mean
metadata2$logD1517 <- log10(metadata2$D1517)
sum_stat <- metadata2 %>% group_by(Soil) %>% rstatix::get_summary_stats(logD1517, show = c("mean", "sd", "se"))
n = ( (2 * sum_stat$sd) / sum_stat$se )^2
sum_stat

print(paste("Based on this simplified formula to compute the minimum number of samples (see link)", round(n[1],0), "samples are needed for the Kurosol and",round(n[2],0),"samples are needed for the Chromosol"))
```
Result:  
At a fixed 95% confidence the Kurosol requires more samples as the SE is lower in this soil. So despite that the values in the Chromosol are more variable, less samples are apparently required. Thus one can be 95% confident that the values are more variable in the Chromosol and fall between a wider value range x~1~...x~n~ ? If so, then it does not seem appropriate to use this simplified calculation which uses the standard error and another method is needed. 


# Confidence Intervals
## Using groupwiseMean function (including bootstrapping)
```{r ce, include=TRUE, message=FALSE, echo=TRUE}

# Get bootstrapped confidence interval for dieldrin concentrations per sample.
rcompanion::groupwiseMean(D1517 ~ 1, data = metadata2, conf = 0.95, digits = 3,
                          boot = TRUE, R = 1000)

# Get bootstrapped confidence interval per soil
rcompanion::groupwiseMean(D1517 ~ Soil, data = metadata2, conf = 0.95, digits = 3,
                          boot = TRUE, R = 1000)

# Group data by paddock and select dieldrin loss - n = 12
meandata <- metadata2 %>% group_by(Soil, Paddock) %>% summarise(Dlossmean = mean(Dloss))
meandata %>% group_by(Soil) %>% get_summary_stats(Dlossmean, type = "mean_se")

# Test normality of dieldrin loss n = 12
shapiro.test(meandata$Dlossmean)

# Get bootstrapped confidence interval of dieldrin loss per paddock
rcompanion::groupwiseMean(Dlossmean ~ 1, data = meandata, conf = 0.95, digits = 3,
              boot = TRUE, R = 1000)

```

## Bootstrap for confidence intervals of the mean and median difference 
**Using the percentile method**
```{r ce2, include=TRUE, message=FALSE, echo=TRUE}
# Ideas mostly from MarinStatsLectures-R Programming & Statistics  -https://www.youtube.com/watch?v=Om5TMGj9td4

# Calculate the difference in sample means (Chromosol - Kurosol)
Obs.Diff.In.Means <- (metadata2 %>% group_by(Soil) %>% summarise(means = mean(D1517)) %>% filter(Soil == "Chromosol"))$means - 
          (metadata2 %>% group_by(Soil) %>% summarise(means = mean(D1517)) %>% filter(Soil == "Kurosol"))$means
print(paste("On average the dieldrin concentrations in the Chromosol were ", round(Obs.Diff.In.Means,2), "µg/g higher"))

Obs.Diff.In.Medians <- (metadata2 %>% group_by(Soil) %>% summarise(means = median(D1517)) %>% filter(Soil == "Chromosol"))$means - 
          (metadata2 %>% group_by(Soil) %>% summarise(means = median(D1517)) %>% filter(Soil == "Kurosol"))$means
print(paste("The median dieldrin concentrations in the Chromosol were ", round(Obs.Diff.In.Medians,2), "µg/g higher"))

set.seed(13579)
n.c <- 10 # the number of observations to sample from the Chromosol
n.k <- 8 # the number of observations to sample form the Kurosol
B <- 10000 # The number of bootstrap samples-- go big or go home

# now, get bootstrap samples for each soil separately (the CI used the observed (samples) values as point of reference)
Boot.chrom <- matrix( sample((metadata2 %>% dplyr::filter(Soil == "Chromosol") %>% dplyr::select(D1517))$D1517, 
                             size = B*n.c, replace = TRUE), ncol = B, nrow = n.c ) 

Boot.kur <- matrix( sample( (metadata2 %>% dplyr::filter(Soil == "Kurosol") %>% dplyr::select(D1517))$D1517 , 
                             size = B*n.k, replace = TRUE), ncol = B, nrow = n.k ) 

# check those
#dim(Boot.chrom ); dim(Boot.kur )

# calculate the differences in MEANS for each of the bootsamples
Boot.Diff.In.Means <- colMeans(Boot.chrom) - colMeans(Boot.kur)

# calculate the differences in MEDIANS for each of the bootsamples
Boot.Diff.In.Median <- apply(Boot.chrom, MARGIN = 2, FUN=median) - apply(Boot.kur, MARGIN = 2, FUN=median)

# Make the confidence interval (using the 95% confidence)

#Percentile Method
#quantile(Boot.Diff.In.Means, prob=0.025)
#quantile(Boot.Diff.In.Means, prob=0.975)

print(paste("We are 95% confident that the mean dieldrin concentrations in the Chromosol were somewhere between ", round(quantile(Boot.Diff.In.Means, prob=0.025),2), "µg/g and", round(quantile(Boot.Diff.In.Means, prob=0.975),2), "higher than the Kurosol"))

#quantile(Boot.Diff.In.Median, prob=0.025)
#quantile(Boot.Diff.In.Median, prob=0.975)
print(paste("We are 95% confident that the median dieldrin concentrations in the Chromosol were somewhere between ", round(quantile(Boot.Diff.In.Median, prob=0.025),2), "µg/g and", round(quantile(Boot.Diff.In.Median, prob=0.975),2), "higher than the Kurosol"))

```


# References
